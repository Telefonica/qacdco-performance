# QA Performance Tool Calling Function

OpenWebUI **Pipe Function** que implementa **native tool calling** para anÃ¡lisis de performance QA via LiteLLM proxy con integraciÃ³n automÃ¡tica con MCPs.

## ğŸ¯ **QuÃ© hace**

FunciÃ³n **manifold** que aparece como modelo `qa-perf/gpt-4` en OpenWebUI y ejecuta automÃ¡ticamente herramientas MCP para anÃ¡lisis de performance testing.

### **Capacidades principales:**
- âœ… **Tool calling nativo** con streaming
- âœ… **Iteraciones automÃ¡ticas** (mÃ¡x 5) hasta completar anÃ¡lisis
- âœ… **IntegraciÃ³n LiteLLM**: VÃ­a proxy unificado
- âœ… **Status updates** en tiempo real
- âœ… **Desplegables** para resultados de herramientas

## ğŸš€ **InstalaciÃ³n en OpenWebUI**

### **1. Copiar funciÃ³n**
1. Ve a **Admin Panel â†’ Functions â†’ Create New Function**
2. Copia todo el contenido de `qa_performance_tool_calling.py`
3. **Pega** en el editor y **Guarda**

### **2. Configurar Valves**
En la funciÃ³n creada, configura las **Valves**:

```yaml
LITELLM_BASE_URL: http://litellm:4000
LITELLM_API_KEY: sk-1234
MODEL_IDS: ["gpt-4"]                 # Modelos disponibles
MAX_ITERATIONS: 5                    # MÃ¡ximo iteraciones
```

### **3. Activar MCPs**
En **Admin Panel â†’ Settings â†’ Models**, habilita los MCPs:
- âœ… `mcp_server_mysql`
- âœ… `mcp-performance-reporter`

## ğŸ“Š **CÃ³mo funciona**

### **Flujo automÃ¡tico:**
```
Usuario: "Analiza ejecuciÃ³n 6994"
     â†“
ğŸ”„ FunciÃ³n detecta necesidad de datos
     â†“
ğŸ› ï¸ Tool Call 1: mysql_query â†’ Obtiene mÃ©tricas
     â†“
ğŸ› ï¸ Tool Call 2: get_report_link â†’ Verifica reportes
     â†“
ğŸ“Š AnÃ¡lisis completo con datos reales
```

### **Interface rica:**
- **Status updates**: `ğŸ”„ AnÃ¡lisis iterativo - IteraciÃ³n 1/5`
- **Tool execution**: `ğŸ” Ejecutando mysql_query...`
- **Desplegables**: ParÃ¡metros y resultados formateados
- **CompletiÃ³n**: `âœ… AnÃ¡lisis completado`

## ğŸ¯ **Ejemplos de uso**

### **AnÃ¡lisis de performance:**
```
"Analiza la ejecuciÃ³n 6994"
"Compara TPS entre ejecuciÃ³n 6835 y 6824"
"Â¿QuÃ© mÃ©tricas tiene el dataset Consume IP mockbin API?"
```

### **GestiÃ³n de reportes:**
```
"Dame el link de descarga del reporte 6994"
"Â¿QuÃ© reportes estÃ¡n disponibles para la ejecuciÃ³n 6835?"
"Lista los Ãºltimos 5 reportes generados"
```

## âš™ï¸ **ConfiguraciÃ³n avanzada**

### **Ajustar iteraciones:**
```yaml
MAX_ITERATIONS: 3  # Menos iteraciones para respuestas mÃ¡s rÃ¡pidas
```

### **Configurar otros proveedores:**
En LiteLLM (`config/litellm_config.yaml`) puedes configurar diferentes proveedores:
```yaml
model_list:
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-4  # Azure OpenAI
      # model: openai/gpt-4  # OpenAI directo
      # model: anthropic/claude-3  # Anthropic
```

## ğŸ”§ **Requisitos**

### **Sistema funcionando:**
- âœ… Docker compose con LiteLLM, MCPs y OpenWebUI
- âœ… MCPs configurados y funcionando
- âœ… Base de datos `qaperformance` accesible

### **En OpenWebUI:**
- âœ… FunciÃ³n copiada e instalada
- âœ… Valves configuradas correctamente
- âœ… MCPs activados en settings

## ğŸš¨ **Troubleshooting**

### **FunciÃ³n no aparece como modelo:**
- Verificar que es tipo `manifold`
- Revisar logs de OpenWebUI
- Reiniciar contenedor OpenWebUI

### **Tool calls no funcionan:**
- Verificar MCPs en Settings â†’ Models
- Comprobar conectividad: `curl http://localhost:8000`
- Revisar logs de contenedores MCP

### **Error de API:**
- Verificar URLs en Valves
- Comprobar LiteLLM: `curl http://localhost:4000/models`
- Verificar API keys vÃ¡lidas
