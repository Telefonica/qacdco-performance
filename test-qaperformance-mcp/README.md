# QA Performance MCP System

Sistema completo de anÃ¡lisis de performance QA que utiliza **OpenWebUI** + **LiteLLM** + **MCPs** + **Azure OpenAI** para proporcionar anÃ¡lisis inteligente y automatizado de mÃ©tricas de testing de performance.

## ğŸ¯ **QuÃ© hace este sistema**

Plataforma conversacional que permite analizar datos de performance testing mediante **IA** con acceso directo a:
- **Base de datos MySQL** con mÃ©tricas histÃ³ricas de performance
- **Sistema de reportes** Django para descarga de informes
- **Tool calling nativo** para anÃ¡lisis automÃ¡tico e iterativo

### **Capacidades principales:**
- âœ… **AnÃ¡lisis comparativo** de ejecuciones de testing
- âœ… **DetecciÃ³n automÃ¡tica** de regresiones y cuellos de botella
- âœ… **GeneraciÃ³n de grÃ¡ficas** comparativas (TPS, latencia, error rates)
- âœ… **Links de descarga** de reportes DOCX automÃ¡ticos
- âœ… **Consultas SQL** especializadas automÃ¡ticas
- âœ… **AnÃ¡lisis iterativo** hasta obtener respuestas completas
- âœ… **Consultas PromQL** a Prometheus para mÃ©tricas en tiempo real
- âœ… **AnÃ¡lisis de targets** y disponibilidad de servicios

## ğŸ—ï¸ **Arquitectura del sistema**

```
Usuario â†” OpenWebUI â†” LiteLLM â†” Azure OpenAI GPT-4
             â†“
        MCP Servers:
         â”œâ”€ MySQL MCP â†’ Base de datos qaperformance
         â”œâ”€ Performance Reporter MCP â†’ Sistema Django reportes
         â””â”€ Prometheus MCP â†’ MÃ©tricas en tiempo real
```

### **Componentes:**

| Servicio | Puerto | DescripciÃ³n |
|----------|--------|-------------|
| **OpenWebUI** | 3000 | Frontend conversacional con IA |
| **LiteLLM** | 4000 | Proxy unificado a Azure OpenAI |
| **MCP MySQL** | 8000 | Servidor MCP para base de datos QA |
| **MCP Performance Reporter** | 8001 | Servidor MCP para gestiÃ³n de reportes |
| **MCP Prometheus** | 8002 | Servidor MCP para mÃ©tricas de Prometheus |

## ğŸš€ **Inicio rÃ¡pido**

### **1. ConfiguraciÃ³n inicial**
```bash
# Clonar y entrar al directorio
cd test-qaperformance-mcp

# Crear archivo .env
cp .env.example .env
# Editar .env con tus credenciales
```

### **2. Iniciar sistema**
```bash
# Construir e iniciar todos los servicios
docker-compose up -d --build

# Verificar estado de servicios
docker-compose ps
```

### **3. Acceso**
- **OpenWebUI**: http://localhost:3000
- **LiteLLM API**: http://localhost:4000

### **4. Configurar en OpenWebUI**
1. **Subir funciÃ³n**: Copiar `functions/qa_performance_tool_calling.py` en **Admin â†’ Functions**
2. **Activar MCPs**: Habilitar en **Settings â†’ Models**
3. **Usar modelo**: Seleccionar `qa-perf/gpt-4` en conversaciones

## ğŸ’¡ **Ejemplos de uso**

### **AnÃ¡lisis comparativo:**
```
"Genera una grÃ¡fica comparativa de TPS entre ejecuciÃ³n 6835 y 6824 del mÃ³dulo LALIGA"
```

### **DetecciÃ³n de problemas:**
```
"Â¿Por quÃ© fallÃ³ la ejecuciÃ³n 6994? Analiza mÃ©tricas y errores"
```

### **GestiÃ³n de reportes:**
```
"Dame el link de descarga del reporte de la ejecuciÃ³n 6994"
```

### **AnÃ¡lisis histÃ³rico:**
```
"Compara las Ãºltimas 5 ejecuciones del dataset Consume IP mockbin API"
```

### **Consultas a Prometheus:**
```
"Â¿CuÃ¡l es el uso de CPU actual de los servicios en producciÃ³n?"
```

```
"Muestra las mÃ©tricas de latencia HTTP de las Ãºltimas 24 horas"
```

## ğŸ“Š **Base de datos QA Performance**

### **Tablas principales:**
- `performance_performanceproject`: Proyectos de testing
- `performance_performanceexecution`: Ejecuciones de pruebas
- `performance_performancemetrics`: MÃ©tricas agregadas (P90, P95, P99, TPS)
- `performance_performancedataset`: Conjuntos de datos de mÃ©tricas
- `performance_performancerawdata`: Datos granulares de tiempo de respuesta

### **MÃ©tricas analizadas:**
- **Tiempos de respuesta**: Mediana, P90, P95, P99
- **Throughput**: Transacciones por segundo (TPS)
- **Error rates**: Tasas de error por transacciÃ³n
- **DistribuciÃ³n de carga**: MÃ©tricas por nÃºmero de hilos
- **Comparaciones histÃ³ricas**: Baselines y regresiones

## ğŸ”§ **ConfiguraciÃ³n avanzada**

### **Variables de entorno (.env):**
```bash
# Clave secreta OpenWebUI (generar con: openssl rand -base64 32)
WEBUI_SECRET_KEY=your-secret-key-here

# ConfiguraciÃ³n MySQL (ya configurada para entorno QA)
MYSQL_HOST=10.95.132.195
MYSQL_USER=qawebservices
MYSQL_PASS=QAteam321.
MYSQL_DB=qaperformance

# API Django reportes
DJANGO_API_BASE=http://qacdco.hi.inet
API_TIMEOUT=30

# Prometheus
PROMETHEUS_URL=http://qacdo-performance-prometheus-qacdo-services-pre.apps.ocp-epg.hi.inet/
PROMETHEUS_URL_SSL_VERIFY=false
PROMETHEUS_DISABLE_LINKS=false
```

### **ConfiguraciÃ³n LiteLLM (`config/litellm_config.yaml`):**
```yaml
model_list:
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-4-deployment-name
      api_base: https://your-instance.openai.azure.com
      api_key: os.environ/AZURE_OPENAI_API_KEY
      api_version: "2024-02-01"
```

## ğŸ“ **Estructura del proyecto**

```
test-qaperformance-mcp/
â”œâ”€â”€ docs/                           # ğŸ“š DocumentaciÃ³n
â”‚   â”œâ”€â”€ system-prompts/            # System prompts especializados
â”‚   â”œâ”€â”€ architecture/              # Diagramas de arquitectura
â”‚   â””â”€â”€ TODO.md                    # Roadmap y mejoras
â”œâ”€â”€
â”œâ”€â”€ functions/                      # âš™ï¸ OpenWebUI Functions
â”‚   â””â”€â”€ qa_performance_tool_calling.py  # FunciÃ³n principal
â”œâ”€â”€
â”œâ”€â”€ mcps/                          # ğŸ”Œ MCP Servers
â”‚   â”œâ”€â”€ mysql/                     # Servidor MCP MySQL
â”‚   â”œâ”€â”€ performance-reporter/      # Servidor MCP reportes
â”‚   â””â”€â”€ prometheus/                # Servidor MCP Prometheus
â”œâ”€â”€
â”œâ”€â”€ config/                        # âš™ï¸ Configuraciones
â”‚   â””â”€â”€ litellm_config.yaml       # Config LiteLLM
â”œâ”€â”€
â””â”€â”€ docker-compose.yml             # ğŸ³ OrquestaciÃ³n servicios
```

## ğŸ”’ **Seguridad y limitaciones**

### **Medidas de seguridad:**
- âœ… **Solo lectura** en operaciones crÃ­ticas de BD
- âœ… **Credenciales limitadas** al entorno de testing
- âœ… **Aislamiento** por contenedores Docker
- âœ… **Variables de entorno** para secretos

### **Limitaciones actuales:**
- **Acceso limitado** a base de datos especÃ­fica `qaperformance`
- **Solo reportes** disponibles en sistema Django
- **Dependencia** de disponibilidad de Azure OpenAI

## ğŸ› ï¸ **Comandos Ãºtiles**

### **GestiÃ³n de servicios:**
```bash
# Iniciar sistema
docker-compose up -d

# Ver logs en tiempo real
docker-compose logs -f

# Reiniciar servicio especÃ­fico
docker-compose restart mcp-mysql

# Detener todo
docker-compose down

# Limpiar volÃºmenes (reset completo)
docker-compose down -v
```

### **Verificar conectividad:**
```bash
# LiteLLM
curl http://localhost:4000/models

# MCP MySQL
curl http://localhost:8000

# MCP Performance Reporter
curl http://localhost:8001

# MCP Prometheus
curl http://localhost:8002

# OpenWebUI
curl http://localhost:3000
```

## ğŸ“ˆ **Casos de uso**

### **Para analistas QA:**
- ComparaciÃ³n de rendimiento entre versiones
- IdentificaciÃ³n de regresiones de performance
- AnÃ¡lisis de distribuciÃ³n de tiempos de respuesta
- DetecciÃ³n de transacciones problemÃ¡ticas

### **Para DevOps:**
- Monitoreo de tendencias de capacidad
- AnÃ¡lisis de estabilidad del sistema
- OptimizaciÃ³n de recursos basada en mÃ©tricas histÃ³ricas

### **Para gestiÃ³n:**
- Reportes ejecutivos de performance
- AnÃ¡lisis de costos de testing
- MÃ©tricas de calidad y SLAs

## ğŸš¨ **Troubleshooting**

### **OpenWebUI no arranca:**
- Verificar `WEBUI_SECRET_KEY` en `.env`
- Comprobar puertos disponibles
- Revisar logs: `docker-compose logs open-webui`

### **MCPs no funcionan:**
- Verificar conectividad a base de datos
- Comprobar credenciales MySQL en `.env`
- Revisar logs MCP: `docker-compose logs mcp-mysql`

### **LiteLLM errores:**
- Verificar configuraciÃ³n Azure OpenAI en `config/litellm_config.yaml`
- Comprobar API keys vÃ¡lidas
- Test directo: `curl http://localhost:4000/models`

---

**ğŸ¯ Objetivo:** Sistema defensivo para anÃ¡lisis inteligente de mÃ©tricas QA que combina IA conversacional moderna con acceso directo a datos especializados de performance testing.